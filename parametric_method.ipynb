{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "envir = 'upright'\n",
    "GAP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flattened_diff_D_db(ref_pitch, ref_vel, var_pitch, var_vel, envir):\n",
    "   \n",
    "    ref_D_db = np.load(f\"data/recordings/{envir}-slice-spec-npy/dictspec_{envir}_p={ref_pitch}_v={ref_vel}.npy\")\n",
    "    var_D_db = np.load(f\"data/recordings/{envir}-slice-spec-npy/dictspec_{envir}_p={var_pitch}_v={var_vel}.npy\")\n",
    "    # ref_D_db, ref_onset = calculate_db_onset(ref_pitch, ref_vel, envir)\n",
    "    # var_D_db, var_onset = calculate_db_onset(var_pitch, var_vel, envir)\n",
    "\n",
    "    diff_D_db = var_D_db - ref_D_db\n",
    "    # diff_D_db = var_D_db[:, var_onset:var_onset + GAP] - ref_D_db[:, ref_onset:ref_onset + GAP]\n",
    "\n",
    "    nf, nt = diff_D_db.shape\n",
    "    diff_D_db_flatten = np.reshape(diff_D_db, nf * nt)\n",
    "\n",
    "    return diff_D_db_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6804baf25042a9b7d0acaf2b628c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673035\n"
     ]
    }
   ],
   "source": [
    "if envir == 'upright':\n",
    "    fail_dict = {\n",
    "        21: list(range(0, 25)),\n",
    "        38: list(range(0, 25)),\n",
    "        39: list(range(0, 36)),\n",
    "        40: list(range(0, 30)),\n",
    "        45: list(range(0, 26)),\n",
    "        46: list(range(0, 32)),\n",
    "        51: list(range(0, 31)),\n",
    "        55: list(range(0, 25)),\n",
    "        72: list(range(0, 66))\n",
    "    }\n",
    "else:\n",
    "    fail_dict = {\n",
    "        52: list(range(112, 128)),\n",
    "        60: list(range(109, 128)),\n",
    "        64: list(range(99, 128)),\n",
    "        78: list(range(121, 128)),\n",
    "    }\n",
    "\n",
    "# pair data collected from condition 1\n",
    "incremental_X = []\n",
    "incremental_y = []\n",
    "incremental_info = []\n",
    "for p in trange(21, 109):\n",
    "\n",
    "    for ref_vel in range(1, 127, 1):\n",
    "\n",
    "        for var_vel in range(ref_vel + 1, 128, 1):\n",
    "\n",
    "            #  check whether the current key(pitch, velocity) is failed\n",
    "            if p in fail_dict and (ref_vel in fail_dict[p] or var_vel in fail_dict[p]):\n",
    "                continue\n",
    "\n",
    "            ref_pitch = p\n",
    "            var_pitch = p\n",
    "\n",
    "            incremental_info.append([ref_pitch, ref_vel, var_pitch, var_vel])\n",
    "\n",
    "            diff_D_db_flatten = get_flattened_diff_D_db(ref_pitch, ref_vel, var_pitch, var_vel, envir)\n",
    "\n",
    "            incremental_X.append(diff_D_db_flatten)\n",
    "            incremental_y.append(1)\n",
    "\n",
    "print(len(incremental_y))\n",
    "\n",
    "# np.save(f\"{envir}/incremental_X.npy\", incremental_X)\n",
    "# np.save(f\"{envir}/incremental_y.npy\", incremental_y)\n",
    "# np.save(f\"{envir}/incremental_info.npy\", incremental_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fd7c7959364e76a9b238c908f87c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pair data collected from condition 2\n",
    "pse_data = pd.read_csv(f'data/experiments/all_pse_{envir}.csv')\n",
    "    \n",
    "pse_dict = {\n",
    "    21: {32: [], 44: [], 60: [], 80: []},\n",
    "    33: {32: [], 44: [], 60: [], 80: []},\n",
    "    45: {32: [], 44: [], 60: [], 80: []},\n",
    "    57: {32: [], 44: [], 60: [], 80: []},\n",
    "    69: {32: [], 44: [], 60: [], 80: []},\n",
    "    81: {32: [], 44: [], 60: [], 80: []},\n",
    "    93: {32: [], 44: [], 60: [], 80: []},\n",
    "    105: {32: [], 44: [], 60: [], 80: []},\n",
    "    108: {32: [], 44: [], 60: [], 80: []},\n",
    "}\n",
    "    \n",
    "pse_pitch_range = pse_data['pitch']\n",
    "pse_vel_range = [32, 44, 60, 80]\n",
    "for d in pse_data:\n",
    "    if d == 'pitch':\n",
    "        continue\n",
    "    else:\n",
    "        vel = int(d.split('_')[1])\n",
    "        data = pse_data[d]\n",
    "        for i, pse in enumerate(data):\n",
    "            pse_dict[pse_pitch_range[i]][vel].append(pse)\n",
    "    \n",
    "mapping = {}\n",
    "for p in pse_pitch_range:\n",
    "    mapping[p] = [0]\n",
    "    for v in pse_vel_range:\n",
    "\n",
    "        pse_min = int(np.percentile(pse_dict[p][v], 25))\n",
    "        pse_max = int(np.percentile(pse_dict[p][v], 75))\n",
    "\n",
    "        mapping[p].append(pse_min)\n",
    "        mapping[p].append(pse_max)\n",
    "    if mapping[p][-1] != 127:\n",
    "        mapping[p].append(127)\n",
    "\n",
    "experimental_X = []\n",
    "experimental_y = []\n",
    "experimental_info = []\n",
    "\n",
    "for ref_pitch_idx, ref_pitch in enumerate(tqdm(pse_pitch_range)):\n",
    "\n",
    "    for ref_vel in range(1, 128):\n",
    "\n",
    "        category = 0\n",
    "        for v in mapping[ref_pitch]:\n",
    "            if ref_vel > v:\n",
    "                category += 1\n",
    "            else:\n",
    "                category -= 1\n",
    "                break\n",
    "\n",
    "        for var_pitch in pse_pitch_range[ref_pitch_idx + 1:]:\n",
    "\n",
    "            for var_vel in range(1, 128, 1):\n",
    "\n",
    "                #  check whether the current key(pitch, velocity) is failed\n",
    "                if var_pitch in fail_dict and var_vel in fail_dict[var_pitch]:\n",
    "                    continue\n",
    "\n",
    "                if category > 0 and var_vel < mapping[var_pitch][category - 1]:\n",
    "                    experimental_y.append(0)\n",
    "                elif var_vel > mapping[var_pitch][category + 1]:\n",
    "                    experimental_y.append(1)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                diff_D_db_flatten = get_flattened_diff_D_db(ref_pitch, ref_vel, var_pitch, var_vel, envir)\n",
    "\n",
    "                experimental_info.append([ref_pitch, ref_vel, var_pitch, var_vel])\n",
    "\n",
    "                experimental_X.append(diff_D_db_flatten)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "incremental_train_X, incremental_test_X, \\\n",
    "incremental_train_y, incremental_test_y = train_test_split(incremental_X, incremental_y, test_size=0.20,\n",
    "                                                                random_state=520)\n",
    "incremental_train_info, incremental_test_info = train_test_split(incremental_info, test_size=0.20, random_state=520)\n",
    "\n",
    "experimental_train_X, experimental_test_X, \\\n",
    "experimental_train_y, experimental_test_y = train_test_split(experimental_X, experimental_y, test_size=0.20, random_state=520)\n",
    "experimental_train_info, experimental_test_info = train_test_split(experimental_info, test_size=0.20, random_state=520)\n",
    "\n",
    "train_X = np.concatenate((experimental_train_X, incremental_train_X), axis=0)\n",
    "train_y = np.concatenate((experimental_train_y, incremental_train_y), axis=0)\n",
    "\n",
    "test_X = np.concatenate((experimental_test_X, incremental_test_X), axis=0)\n",
    "test_y = np.concatenate((experimental_test_y, incremental_test_y), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9121145259904759 0.979269704303904\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(\n",
    "    max_iter=1000000,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    fit_intercept=False,\n",
    ").fit(train_X, train_y)\n",
    "\n",
    "# save\n",
    "with open(f'model_without_intercept.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "train_acc = metrics.accuracy_score(incremental_test_y, model.predict(incremental_test_X))\n",
    "test_acc = metrics.accuracy_score(experimental_test_y, model.predict(experimental_test_X))\n",
    "print(train_acc, test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ceda3cc1039bf75f799afb7cfb6768edb546cdd6d1965e0332a04c99899815e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
